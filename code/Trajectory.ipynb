{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib as mpl\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "import json\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import collections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CALL_TYPE</th>\n",
       "      <th>ORIGIN_CALL</th>\n",
       "      <th>ORIGIN_STAND</th>\n",
       "      <th>TAXI_ID</th>\n",
       "      <th>TIMESTAMP</th>\n",
       "      <th>POLYLINE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20000589</td>\n",
       "      <td>1372636858</td>\n",
       "      <td>[[-8.618643, 41.141412], [-8.618499, 41.141376...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>20000596</td>\n",
       "      <td>1372637303</td>\n",
       "      <td>[[-8.639847, 41.159826], [-8.640351, 41.159871...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20000320</td>\n",
       "      <td>1372636951</td>\n",
       "      <td>[[-8.612964, 41.140359], [-8.613378, 41.14035]...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20000520</td>\n",
       "      <td>1372636854</td>\n",
       "      <td>[[-8.574678, 41.151951], [-8.574705, 41.151942...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20000337</td>\n",
       "      <td>1372637091</td>\n",
       "      <td>[[-8.645994, 41.18049], [-8.645949, 41.180517]...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  CALL_TYPE  ORIGIN_CALL  ORIGIN_STAND   TAXI_ID   TIMESTAMP  \\\n",
       "0         C          NaN           NaN  20000589  1372636858   \n",
       "1         B          NaN             7  20000596  1372637303   \n",
       "2         C          NaN           NaN  20000320  1372636951   \n",
       "3         C          NaN           NaN  20000520  1372636854   \n",
       "4         C          NaN           NaN  20000337  1372637091   \n",
       "\n",
       "                                            POLYLINE  \n",
       "0  [[-8.618643, 41.141412], [-8.618499, 41.141376...  \n",
       "1  [[-8.639847, 41.159826], [-8.640351, 41.159871...  \n",
       "2  [[-8.612964, 41.140359], [-8.613378, 41.14035]...  \n",
       "3  [[-8.574678, 41.151951], [-8.574705, 41.151942...  \n",
       "4  [[-8.645994, 41.18049], [-8.645949, 41.180517]...  "
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read data\n",
    "zf = zipfile.ZipFile('train.csv.zip')\n",
    "df = pd.read_csv(zf.open('train.csv'), nrows = 10000, converters = {'POLYLINE': lambda x: json.loads(x)})\n",
    "df = df.drop(['MISSING_DATA', 'TRIP_ID', 'DAY_TYPE'], 1)\n",
    "print df.shape\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CALL_TYPE</th>\n",
       "      <th>ORIGIN_CALL</th>\n",
       "      <th>ORIGIN_STAND</th>\n",
       "      <th>TAXI_ID</th>\n",
       "      <th>TIMESTAMP</th>\n",
       "      <th>POLYLINE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20000589</td>\n",
       "      <td>07-01 07</td>\n",
       "      <td>[[-8.618643, 41.141412], [-8.618499, 41.141376...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>20000596</td>\n",
       "      <td>07-01 07</td>\n",
       "      <td>[[-8.639847, 41.159826], [-8.640351, 41.159871...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20000320</td>\n",
       "      <td>07-01 07</td>\n",
       "      <td>[[-8.612964, 41.140359], [-8.613378, 41.14035]...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20000520</td>\n",
       "      <td>07-01 07</td>\n",
       "      <td>[[-8.574678, 41.151951], [-8.574705, 41.151942...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20000337</td>\n",
       "      <td>07-01 07</td>\n",
       "      <td>[[-8.645994, 41.18049], [-8.645949, 41.180517]...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  CALL_TYPE  ORIGIN_CALL  ORIGIN_STAND   TAXI_ID TIMESTAMP  \\\n",
       "0         C          NaN           NaN  20000589  07-01 07   \n",
       "1         B          NaN             7  20000596  07-01 07   \n",
       "2         C          NaN           NaN  20000320  07-01 07   \n",
       "3         C          NaN           NaN  20000520  07-01 07   \n",
       "4         C          NaN           NaN  20000337  07-01 07   \n",
       "\n",
       "                                            POLYLINE  \n",
       "0  [[-8.618643, 41.141412], [-8.618499, 41.141376...  \n",
       "1  [[-8.639847, 41.159826], [-8.640351, 41.159871...  \n",
       "2  [[-8.612964, 41.140359], [-8.613378, 41.14035]...  \n",
       "3  [[-8.574678, 41.151951], [-8.574705, 41.151942...  \n",
       "4  [[-8.645994, 41.18049], [-8.645949, 41.180517]...  "
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change unix timestamp to form \"%m-%d-%H\"\n",
    "for i in range(0, df.shape[0]):\n",
    "    if isinstance(df['TIMESTAMP'][i], int):\n",
    "        df.TIMESTAMP = df.TIMESTAMP.replace(df['TIMESTAMP'][i],\n",
    "                                            datetime.fromtimestamp(df['TIMESTAMP'][i]).strftime('%m-%d %H'))\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Descricao</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Agra</td>\n",
       "      <td>41.1771457135</td>\n",
       "      <td>-8.609670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Alameda</td>\n",
       "      <td>41.15618964</td>\n",
       "      <td>-8.591064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Aldoar</td>\n",
       "      <td>41.1705249231</td>\n",
       "      <td>-8.665876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Alfândega</td>\n",
       "      <td>41.1437639911</td>\n",
       "      <td>-8.621803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Amial</td>\n",
       "      <td>41.1835097223</td>\n",
       "      <td>-8.612726</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  Descricao       Latitude  Longitude\n",
       "0   1       Agra  41.1771457135  -8.609670\n",
       "1   2    Alameda    41.15618964  -8.591064\n",
       "2   3     Aldoar  41.1705249231  -8.665876\n",
       "3   4  Alfândega  41.1437639911  -8.621803\n",
       "4   5      Amial  41.1835097223  -8.612726"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read meta stand data\n",
    "zf = zipfile.ZipFile('metaData_taxistandsID.csv.zip')\n",
    "meta_df = pd.read_csv(zf.open('metaData_taxistandsID_name_GPSlocation.csv'))\n",
    "meta_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CALL_TYPE</th>\n",
       "      <th>ORIGIN_CALL</th>\n",
       "      <th>ORIGIN_STAND</th>\n",
       "      <th>TAXI_ID</th>\n",
       "      <th>TIMESTAMP</th>\n",
       "      <th>POLYLINE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20000589</td>\n",
       "      <td>07-01 07</td>\n",
       "      <td>[[-8.618643, 41.141412], [-8.618499, 41.141376...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Av. Boavista</td>\n",
       "      <td>20000596</td>\n",
       "      <td>07-01 07</td>\n",
       "      <td>[[-8.639847, 41.159826], [-8.640351, 41.159871...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20000320</td>\n",
       "      <td>07-01 07</td>\n",
       "      <td>[[-8.612964, 41.140359], [-8.613378, 41.14035]...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20000520</td>\n",
       "      <td>07-01 07</td>\n",
       "      <td>[[-8.574678, 41.151951], [-8.574705, 41.151942...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20000337</td>\n",
       "      <td>07-01 07</td>\n",
       "      <td>[[-8.645994, 41.18049], [-8.645949, 41.180517]...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  CALL_TYPE  ORIGIN_CALL  ORIGIN_STAND   TAXI_ID TIMESTAMP  \\\n",
       "0         C          NaN           NaN  20000589  07-01 07   \n",
       "1         B          NaN  Av. Boavista  20000596  07-01 07   \n",
       "2         C          NaN           NaN  20000320  07-01 07   \n",
       "3         C          NaN           NaN  20000520  07-01 07   \n",
       "4         C          NaN           NaN  20000337  07-01 07   \n",
       "\n",
       "                                            POLYLINE  \n",
       "0  [[-8.618643, 41.141412], [-8.618499, 41.141376...  \n",
       "1  [[-8.639847, 41.159826], [-8.640351, 41.159871...  \n",
       "2  [[-8.612964, 41.140359], [-8.613378, 41.14035]...  \n",
       "3  [[-8.574678, 41.151951], [-8.574705, 41.151942...  \n",
       "4  [[-8.645994, 41.18049], [-8.645949, 41.180517]...  "
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replace ORIGIN_STAND from a numeric to the name of a city.\n",
    "df.ORIGIN_STAND = df.ORIGIN_STAND.replace(np.array(meta_df.ID), np.array(meta_df.Descricao))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CALL_TYPE</th>\n",
       "      <th>ORIGIN_CALL</th>\n",
       "      <th>ORIGIN_STAND</th>\n",
       "      <th>TAXI_ID</th>\n",
       "      <th>TIMESTAMP</th>\n",
       "      <th>POLYLINE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20000589</td>\n",
       "      <td>07-01 07</td>\n",
       "      <td>[[-861, 4115], [-862, 4115], [-863, 4115], [-8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Av. Boavista</td>\n",
       "      <td>20000596</td>\n",
       "      <td>07-01 07</td>\n",
       "      <td>[[-863, 4116], [-864, 4116], [-864, 4117], [-8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20000320</td>\n",
       "      <td>07-01 07</td>\n",
       "      <td>[[-861, 4115], [-862, 4115], [-863, 4115], [-8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20000520</td>\n",
       "      <td>07-01 07</td>\n",
       "      <td>[[-857, 4116], [-857, 4115], [-858, 4115], [-8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20000337</td>\n",
       "      <td>07-01 07</td>\n",
       "      <td>[[-864, 4119], [-864, 4118], [-865, 4118], [-8...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  CALL_TYPE  ORIGIN_CALL  ORIGIN_STAND   TAXI_ID TIMESTAMP  \\\n",
       "0         C          NaN           NaN  20000589  07-01 07   \n",
       "1         B          NaN  Av. Boavista  20000596  07-01 07   \n",
       "2         C          NaN           NaN  20000320  07-01 07   \n",
       "3         C          NaN           NaN  20000520  07-01 07   \n",
       "4         C          NaN           NaN  20000337  07-01 07   \n",
       "\n",
       "                                            POLYLINE  \n",
       "0  [[-861, 4115], [-862, 4115], [-863, 4115], [-8...  \n",
       "1  [[-863, 4116], [-864, 4116], [-864, 4117], [-8...  \n",
       "2  [[-861, 4115], [-862, 4115], [-863, 4115], [-8...  \n",
       "3  [[-857, 4116], [-857, 4115], [-858, 4115], [-8...  \n",
       "4  [[-864, 4119], [-864, 4118], [-865, 4118], [-8...  "
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replace POLYLINE from a GPS location to a grid chain\n",
    "trajectory_list = list()\n",
    "for cnt in range(0, df.shape[0]):\n",
    "    trajectory = np.array(df['POLYLINE'][cnt])\n",
    "    trajectory = np.ceil(trajectory*100)\n",
    "    i = 0\n",
    "    while i < len(trajectory)-1:\n",
    "        if np.array_equal(trajectory[i], trajectory[i+1]):\n",
    "            trajectory = np.delete(trajectory, i+1, 0)\n",
    "        else:\n",
    "            i = i + 1\n",
    "    trajectory = np.int64(trajectory)\n",
    "    trajectory_list.append(trajectory)\n",
    "\n",
    "df = df.drop(['POLYLINE'], 1)\n",
    "df['POLYLINE'] = trajectory_list\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_csv('new_train.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133005\n"
     ]
    }
   ],
   "source": [
    "words = list()\n",
    "pos_list = list()\n",
    "cnt = 0\n",
    "for i in range(df.shape[0]):\n",
    "    pos_list.append(cnt)\n",
    "    for name in df.columns:\n",
    "        if name != 'POLYLINE':\n",
    "            words.append(str(df[name][i]))\n",
    "            cnt = cnt + 1\n",
    "        else:\n",
    "            for li in df[name][i]:\n",
    "                words.append(str(li))\n",
    "                cnt = cnt + 1\n",
    "\n",
    "print len(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# CBOW\n",
    "predicting the word given its context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Most common words (+UNK)', [['UNK', 0], ('nan', 12576), ('B', 5157), ('[-861 4115]', 4322), ('[-860 4115]', 3105)])\n",
      "('Sample data', [8, 1, 1, 449, 167, 3, 13, 30, 5, 9])\n",
      "12\n",
      "2\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "vocabulary_size = 5000\n",
    "\n",
    "def build_dataset(words):\n",
    "    count = [['UNK', -1]]\n",
    "    count.extend(collections.Counter(words).most_common(vocabulary_size - 1))\n",
    "    dictionary = dict()\n",
    "    for word, _ in count:\n",
    "        dictionary[word] = len(dictionary)\n",
    "    data = list()\n",
    "    unk_count = 0\n",
    "    for word in words:\n",
    "        if word in dictionary:\n",
    "            index = dictionary[word]\n",
    "        else:\n",
    "            index = 0  # dictionary['UNK']\n",
    "            unk_count = unk_count + 1\n",
    "        data.append(index)\n",
    "    count[0][1] = unk_count\n",
    "    reverse_dictionary = dict(zip(dictionary.values(), dictionary.keys())) \n",
    "    return data, count, dictionary, reverse_dictionary\n",
    "\n",
    "data, count, dictionary, reverse_dictionary = build_dataset(words)\n",
    "print('Most common words (+UNK)', count[:5])\n",
    "print('Sample data', data[:10])\n",
    "print(dictionary['A'])\n",
    "print(dictionary['B'])\n",
    "print(dictionary['C'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONTEXT FOR [-863 4116]:\n",
      "C\n",
      "nan\n",
      "nan\n",
      "20000589\n",
      "07-01 07\n",
      "[-861 4115]\n",
      "\n",
      "CONTEXT FOR [-866 4118]:\n",
      "B\n",
      "nan\n",
      "Av. Boavista\n",
      "20000596\n",
      "07-01 07\n",
      "[-863 4116]\n",
      "\n",
      "CONTEXT FOR [-861 4115]:\n",
      "C\n",
      "nan\n",
      "nan\n",
      "20000320\n",
      "07-01 07\n",
      "[-861 4115]\n",
      "\n",
      "CONTEXT FOR [-860 4115]:\n",
      "C\n",
      "nan\n",
      "nan\n",
      "20000520\n",
      "07-01 07\n",
      "[-857 4116]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "start_index = 0\n",
    "\n",
    "def generate_cbow_batch(batch_size, context_size):\n",
    "    batch_size = batch_size * context_size\n",
    "    global start_index\n",
    "  \n",
    "    batch = np.ndarray(shape=(batch_size), dtype=np.int32)\n",
    "    labels = np.ndarray(shape=(batch_size / context_size, 1), dtype=np.int32)\n",
    "\n",
    "    for i in range(batch_size / context_size):\n",
    "        labels[i, 0] = data[pos_list[i+1]-1]\n",
    "        for j in range(context_size):\n",
    "            batch[i*context_size + j] = data[pos_list[i]+j]\n",
    "            \n",
    "    return batch, labels\n",
    "\n",
    "b_size = 24\n",
    "c_size = 6\n",
    "batch, labels = generate_cbow_batch(batch_size=b_size, context_size=c_size)\n",
    "for i in range(b_size / (c_size)):\n",
    "    print \"CONTEXT FOR %s:\" % reverse_dictionary[labels[i,0]]\n",
    "    for j in range(c_size):\n",
    "        print reverse_dictionary[batch[i*(c_size) + j]]\n",
    "    print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### initialization of the graph ###\n",
    "\n",
    "batch_size = 128\n",
    "embedding_size = 128 # Dimension of the embedding vector.\n",
    "context_window = 6 # How many words to consider left and right\n",
    "# We pick a random validation set to sample nearest neighbors. here we limit the\n",
    "# validation samples to the words that have a low numeric ID, which by\n",
    "# construction are also the most frequent. \n",
    "valid_size = 64 # Random set of words to evaluate similarity on.\n",
    "valid_window = 100 # Only pick dev samples in the head of the distribution.\n",
    "valid_examples = np.array(random.sample(xrange(valid_window), valid_size))\n",
    "num_sampled = 64 # Number of negative examples to sample.\n",
    "\n",
    "graph = tf.Graph()\n",
    "\n",
    "with graph.as_default():\n",
    "\n",
    "    # Input data.\n",
    "    train_dataset = tf.placeholder(tf.int32, shape=[batch_size * context_window])\n",
    "    train_labels = tf.placeholder(tf.int32, shape=[batch_size, 1])\n",
    "    valid_dataset = tf.constant(valid_examples, dtype=tf.int32)\n",
    "  \n",
    "    # Variables.\n",
    "    embeddings = tf.Variable(\n",
    "        tf.random_uniform([vocabulary_size, embedding_size], -1.0, 1.0))\n",
    "    segments = tf.constant([x / context_window for x in range(batch_size * context_window)])\n",
    "    softmax_weights = tf.Variable(\n",
    "        tf.truncated_normal([vocabulary_size, embedding_size],\n",
    "                            stddev=1.0 / math.sqrt(embedding_size)))\n",
    "    softmax_biases = tf.Variable(tf.zeros([vocabulary_size]))\n",
    "  \n",
    "    # Model.\n",
    "    # Look up embeddings for inputs.\n",
    "    embed = tf.nn.embedding_lookup(embeddings, train_dataset)\n",
    "    compressed_embeddings = tf.segment_sum(embed, segments) # merging couple of embeded words into one input\n",
    "    # Compute the softmax loss, using a sample of the negative labels each time.\n",
    "    loss = tf.reduce_mean(\n",
    "        tf.nn.sampled_softmax_loss(softmax_weights, softmax_biases, compressed_embeddings,\n",
    "                                   train_labels, num_sampled, vocabulary_size))\n",
    "\n",
    "    # Optimizer.\n",
    "    optimizer = tf.train.AdagradOptimizer(1.0).minimize(loss)\n",
    "  \n",
    "    # Compute the similarity between minibatch examples and all embeddings.\n",
    "    # We use the cosine distance:\n",
    "    norm = tf.sqrt(tf.reduce_sum(tf.square(embeddings), 1, keep_dims=True))\n",
    "    normalized_embeddings = embeddings / norm\n",
    "    valid_embeddings = tf.nn.embedding_lookup(\n",
    "        normalized_embeddings, valid_dataset)\n",
    "    similarity = tf.matmul(valid_embeddings, tf.transpose(normalized_embeddings))\n",
    "    \n",
    "    input = [dictionary['C'], dictionary['nan'], dictionary['Av. Boavista'], dictionary['20000320'],\n",
    "             dictionary['07-01 11'], dictionary['[-861 4115]']] * batch_size\n",
    "    logits = tf.matmul(compressed_embeddings, tf.transpose(softmax_weights)) + softmax_biases\n",
    "    y_ = tf.nn.softmax(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Average loss at step 0: 8.135115\n",
      "Average loss at step 2000: 4.175498\n",
      "Average loss at step 4000: 0.127605\n",
      "Average loss at step 6000: 0.083688\n",
      "['[-871 4126]', '[-854 4113]', '[-791 4063]', '[-861 4116]']\n"
     ]
    }
   ],
   "source": [
    "num_steps = 7000\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "    tf.initialize_all_variables().run()\n",
    "    print('Initialized')\n",
    "    average_loss = 0\n",
    "    for step in range(num_steps):\n",
    "        batch_data, batch_labels = generate_cbow_batch(\n",
    "        batch_size, context_window)\n",
    "        feed_dict = {train_dataset : batch_data, train_labels : batch_labels}\n",
    "        _, l = session.run([optimizer, loss], feed_dict=feed_dict)\n",
    "        average_loss += l\n",
    "        if step % 2000 == 0:\n",
    "            if step > 0:\n",
    "                average_loss = average_loss / 2000\n",
    "            # The average loss is an estimate of the loss over the last 2000 batches.\n",
    "            print('Average loss at step %d: %f' % (step, average_loss))\n",
    "            average_loss = 0\n",
    "        # note that this is expensive (~20% slowdown if computed every 500 steps)\n",
    "    \n",
    "    final_embeddings = normalized_embeddings.eval()\n",
    "    # feeds the algorithm a context and gets the most probable autocompletion/autocorrection\n",
    "    feed_dict = {train_dataset : input}\n",
    "    _, y = session.run([logits, y_], feed_dict=feed_dict)\n",
    " \n",
    "    top_k = 4 # number of nearest neighbors\n",
    "    for i in xrange(1):\n",
    "        print [reverse_dictionary[x] for x in (-y[i, :]).argsort()[1:top_k+1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = '[12 34]'\n",
    "int(s.split()[0].split('[')[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
